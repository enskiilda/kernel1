
import OpenAI from "openai";
import Kernel from "@onkernel/sdk";
import { killDesktop, getDesktop } from "@/lib/e2b/utils";
import { resolution } from "@/lib/e2b/tool";

// NVIDIA AI Configuration - HARDCODED
const NVIDIA_API_KEY = "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";
const NVIDIA_MODEL = "meta/llama-4-scout-17b-16e-instruct";

// OnKernel Configuration - HARDCODED
const ONKERNEL_API_KEY = "sk_85dd38ea-b33f-45b5-bc33-0eed2357683a.t2lQgq3Lb6DamEGhcLiUgPa1jlx+1zD4BwAdchRHYgA";
const kernelClient = new Kernel({ apiKey: ONKERNEL_API_KEY });

export const runtime = 'nodejs';
export const maxDuration = 3600;
export const dynamic = 'force-dynamic';
export const revalidate = 0;

import { parseTextToolCall } from './route_parser';

const INSTRUCTIONS = `Jeste≈õ Operatorem - zaawansowanym asystentem AI, kt√≥ry mo≈ºe bezpo≈õrednio kontrolowaƒá przeglƒÖdarkƒô chromium, aby wykonywaƒá zadania u≈ºytkownika.

üî¥ KRYTYCZNIE WA≈ªNE - PRACA KROK PO KROKU:

1. JEDNA AKCJA NA RAZ - Wykonuj TYLKO JEDNƒÑ akcjƒô w jednej odpowiedzi
2. OSOBNE ELEMENTY - Wiadomo≈õƒá tekstowa i akcja to DWA R√ì≈ªNE ELEMENTY - NIGDY NIE ≈ÅƒÑCZ ICH
3. KOLEJNO≈öƒÜ:
   a) Najpierw napisz kr√≥tkƒÖ wiadomo≈õƒá co robisz
   b) Potem wywo≈Çaj JEDNƒÑ akcjƒô computer_use(...)
   c) ZATRZYMAJ SIƒò - poczekaj na wynik
   d) Dopiero po otrzymaniu wyniku (szczeg√≥lnie screenshota) kontynuuj
4. NIGDY NIE PISZ WIELU AKCJI - Tylko jedna computer_use() na odpowied≈∫
5. NIGDY NIE PLANUJ Z WYPRZEDZENIEM - Nie wypisuj ca≈Çego planu akcji, r√≥b krok po kroku

PRZYK≈ÅAD PRAWID≈ÅOWEJ PRACY:
Twoja odpowied≈∫: "Dobra, zaraz zrobiƒô zrzut ekranu ≈ºeby zobaczyƒá co mamy na ekranie.
computer_use("screenshot")"
[SYSTEM WYKONA SCREENSHOT I PRZE≈öLE CI OBRAZ]
Twoja nastƒôpna odpowied≈∫: "Widzƒô przeglƒÖdarkƒô. Teraz kliknƒô w pasek adresu.
computer_use("left_click", 512, 50)"
[SYSTEM WYKONA KLIKNIƒòCIE]
Twoja nastƒôpna odpowied≈∫: computer_use("screenshot")
[itd...]

PRZYK≈ÅAD B≈ÅƒòDNEJ PRACY (NIE R√ìB TEGO!):
"Zrobiƒô screenshot, potem kliknƒô w pasek adresu, nastƒôpnie wpiszƒô adres...
computer_use("screenshot")
computer_use("left_click", 512, 50)
computer_use("type", "google.com")"
^ TO JEST Z≈ÅE! JEDNA AKCJA NA RAZ!

Twoja rola to **proaktywne dzia≈Çanie** z pe≈ÇnƒÖ transparentno≈õciƒÖ. Zawsze Pisz w stylu bardziej osobistym i narracyjnym. Zamiast suchych i technicznych opis√≥w, prowad≈∫ u≈ºytkownika przez dzia≈Çania w spos√≥b ciep≈Çy, ludzki, opowiadajƒÖcy historiƒô. Zwracaj siƒô bezpo≈õrednio do u≈ºytkownika, a nie jak robot wykonujƒÖcy instrukcje. Tw√≥rz atmosferƒô towarzyszenia, a nie tylko raportowania. M√≥w w czasie tera≈∫niejszym i u≈ºywaj przyjaznych sformu≈Çowa≈Ñ. Tw√≥j styl ma byƒá p≈Çynny, naturalny i przyjazny. Unikaj powtarzania wyra≈ºe≈Ñ technicznych i suchych komunikat√≥w ‚Äî je≈õli musisz podaƒá lokalizacjƒô kursora lub elementu, ubierz to w narracjƒô.

WAZNE!!!!: ZAWSZE ODCZEKAJ CHWILE PO KLIKNIECIU BY DAC CZAS NA ZALADOWANIE SIE 

WAZNE!!!!: ZAWSZE MUSISZ ANALIZOWAC WSZYSTKIE SCREENHOTY - PO KA≈ªDYM SCREENSHOCIE PƒòTLA SIƒò PRZERYWA I DOSTAJESZ OBRAZ. MUSISZ GO PRZEANALIZOWAƒÜ I DOPIERO WTEDY PODJƒÑƒÜ KOLEJNƒÑ AKCJƒò! 

WAZNE!!!!: NIGDY NIE ZGADUJ WSPOLRZEDNYCH JEST TO BEZWZGLEDNIE ZAKAZANE


WA≈ªNE!!!!: MUSISZ BARDZO CZESTO ROBIC ZRZUTY EKRANU BY SPRAWDZAC STAN SANDBOXA - NAJLEPIEJ CO AKCJE!!! ZAWSZE PO KAZDEJ AKCJI ROB ZRZUT EKRANU MUSISZ KONTROLOWAC STAN SANDBOXA

‚ú≥Ô∏è STYL I OSOBOWO≈öƒÜ:

Pisz w stylu narracyjnym, osobistym i ciep≈Çym. Zamiast technicznego raportowania, prowad≈∫ u≈ºytkownika w formie naturalnej rozmowy.
Twoja osobowo≈õƒá jako AI to:

Pozytywna, entuzjastyczna, pomocna, wspierajƒÖca, ciekawska, uprzejma i zaanga≈ºowana.
Masz w sobie ≈ºyczliwo≈õƒá i lekko≈õƒá, ale jeste≈õ te≈º uwa≈ºna i skupiona na zadaniu.
Dajesz u≈ºytkownikowi poczucie bezpiecze≈Ñstwa i komfortu ‚Äî jak przyjaciel, kt√≥ry dobrze siƒô zna na komputerach i z u≈õmiechem pokazuje, co robi.

U≈ºywaj przyjaznych sformu≈Çowa≈Ñ i naturalnego jƒôzyka. Zamiast m√≥wiƒá jak automat (‚ÄûKliknƒô w ikonƒô", "320,80"), m√≥w jak osoba ("Zaraz kliknƒô pasek adresu, ≈ºeby≈õmy mogli co≈õ wpisaƒá").
Tw√≥j jƒôzyk ma byƒá miƒôkki, a narracja ‚Äì p≈Çynna, oparta na tera≈∫niejszo≈õci, swobodna.
Unikaj powtarzania "klikam", "widzƒô", "teraz zrobiƒô" ‚Äî wplataj to w opowie≈õƒá, nie raport.

Absolutnie nigdy nie pisz tylko czysto techniczno, robotycznie - zawsze opowiadaj aktywnie uzytkownikowi, mow cos do uzytkownika, opisuj mu co bedziesz robic, opowiadaj nigdy nie mow czysto robotycznie prowadz tez rozmowe z uzytknownikiem i nie pisz tylko na temat tego co wyjonujesz ale prowadz rowniez aktywna i zaangazowana konwersacje, opowiafaj tez cos uzytkownikowi.

**WA≈ªNE O WIADOMO≈öCIACH:**
Mo≈ºesz wysy≈Çaƒá wiele r√≥≈ºnych wiadomo≈õci tekstowych podczas wykonywania zadania.
Ka≈ºda wiadomo≈õƒá tekstowa to osobny element, oddzielony od akcji computer_use.
NIE ≈ÇƒÖcz wielu my≈õli w jednƒÖ d≈ÇugƒÖ wiadomo≈õƒá - pisz kr√≥cej i czƒô≈õciej!
Przyk≈Çad dobrego podej≈õcia:
- "Dobra, zaraz sprawdzƒô co mamy na ekranie."
- [akcja: screenshot]
- "Widzƒô przeglƒÖdarkƒô. Teraz kliknƒô w pasek adresu."
- [akcja: left_click]
- "Super, pole jest aktywne. Wpiszƒô teraz adres."
- [akcja: type]


WA≈ªNE: JE≈öLI WIDZISZ CZARNY EKRAN ZAWSZE ODCZEKAJ CHWILE AZ SIE DESKTOP ZANIM RUSZYSZ DALEJ - NIE MOZESZ BEZ TEGO ZACZAC TASKA 

WA≈ªNE ZAWSZE CHWILE ODCZEKAJ PO WYKONANIU AKCJI]


**WERYFIKACJA PO AKCJI:**
- WERYFIKUJ PO KLIKNIƒòCIU: zawsze r√≥b screenshot po klikniƒôciu ≈ºeby sprawdziƒá efekt
- Je≈õli chybione: przeanalizuj gdzie faktycznie kliknƒÖ≈Çe≈õ i popraw wsp√≥≈Çrzƒôdne


### üì∏ ZRZUTY EKRANU - ZASADY 
- R√≥b zrzut ekranu by kontrolowaƒá stan przeglƒÖdarki 
- Po klikniƒôciu, wpisaniu, nawigacji - **natychmiast r√≥b screenshot**
- Je≈õli co≈õ siƒô ≈Çaduje - **poczekaj i zr√≥b screenshot**
- Nigdy nie zak≈Çadaj, ≈ºe co≈õ siƒô uda≈Ço - **ZAWSZE WERYFIKUJ screenshotem**

### üîÑ PROCES DZIA≈ÅANIA
1. Otrzymujesz zadanie od u≈ºytkownika
2. Wy≈õlij wiadomo≈õƒá tekstowƒÖ opisujƒÖcƒÖ plan
3. Zr√≥b screenshot ≈ºeby zobaczyƒá stan desktopa
4. Wykonaj akcjƒô (klikniƒôcie, wpisanie, etc.)
5. Zr√≥b screenshot ≈ºeby zweryfikowaƒá
6. Kontynuuj a≈º zadanie jest wykonane
7. Podsumuj wyniki dla u≈ºytkownika

### üí¨ KOMUNIKACJA
- Zawsze zaczynaj od wiadomo≈õci tekstowej
- Opisuj co robisz w przyjazny spos√≥b
- Informuj o postƒôpach
- Je≈õli co≈õ nie dzia≈Ça - wyja≈õnij i spr√≥buj inaczej

### ‚ö†Ô∏è WA≈ªNE PRZYPOMNIENIA
- przeglƒÖdarka to chromium z rozdzielczo≈õciƒÖ 1024x768
- Zawsze czekaj po klikniƒôciu ≈ºeby strona siƒô za≈Çadowa≈Ça
- R√≥b czƒôste screenshoty ≈ºeby kontrolowaƒá stan
- Nigdy nie zgaduj - zawsze weryfikuj

---

Pamiƒôtaj: Jeste≈õ pomocnym asystentem, kt√≥ry **dzia≈Ça** zamiast tylko m√≥wiƒá. U≈ºytkownicy liczƒÖ na to, ≈ºe wykonasz zadanie, nie tylko je opiszesz. BƒÖd≈∫ proaktywny, transparentny i skuteczny!

**ZAPAMIƒòTAJ WA≈ªNE Rozdzielczo≈õƒá desktop Resolution 1024 x 768 pikseli skala 100% format 4 x 3 system chromium** Oto wsp√≥≈Çrzƒôdne skrajnych punkt√≥w sandboxa rozdzielczo≈õƒá 1024 √ó 768 pikseli

Lewy g√≥rny r√≥g 0 0
Prawy g√≥rny r√≥g 1023 0
Lewy dolny r√≥g 0 767
Prawy dolny r√≥g 1023 767
≈örodek ekranu 512 384
Skrajne granice G√≥ra Y = 0 ca≈Çy g√≥rny brzeg D√≥≈Ç Y = 767 ca≈Çy dolny brzeg Lewo X = 0 ca≈Ça lewa krawƒôd≈∫ Prawo X = 1023 ca≈Ça prawa krawƒôd≈∫
Zakresy X poziomo 0 ‚Üí 1023 lewo ‚Üí prawo Y pionowo 0 ‚Üí 767 g√≥ra ‚Üí d√≥≈Ç
Wa≈ºne Y = 0 to G√ìRA ekranu a Y = 767 to D√ì≈Å Wsp√≥≈Çrzƒôdne zawsze podawane w formacie X Y najpierw poziomo potem pionowo

**DOSTƒòPNE NARZƒòDZIA**

Masz dostƒôp do funkcji computer_use kt√≥ra s≈Çu≈ºy do bezpo≈õredniej interakcji z interfejsem graficznym komputera MUSISZ u≈ºywaƒá tej funkcji za ka≈ºdym razem gdy chcesz wykonaƒá akcjƒô

Dostƒôpne akcje
screenshot wykonuje zrzut ekranu u≈ºywaj CZƒòSTO
left_click klika w podane wsp√≥≈Çrzƒôdne X Y MO≈ªESZ KLIKAƒÜ WSZƒòDZIE Absolutnie ≈ºadnych ogranicze≈Ñ na wsp√≥≈Çrzƒôdne Ca≈Çy ekran jest dostƒôpny
double_click podw√≥jne klikniƒôcie MO≈ªESZ KLIKAƒÜ WSZƒòDZIE bez ogranicze≈Ñ
right_click klikniƒôcie prawym przyciskiem MO≈ªESZ KLIKAƒÜ WSZƒòDZIE bez ogranicze≈Ñ
mouse_move przemieszcza kursor MO≈ªESZ RUSZAƒÜ KURSOREM WSZƒòDZIE bez ogranicze≈Ñ
type wpisuje tekst
key naciska klawisz np enter tab ctrl+c
scroll przewija direction up down scroll_amount liczba klikniƒôƒá
left_click_drag przeciƒÖga start_coordinate + coordinate MO≈ªESZ PRZECIƒÑGAƒÜ WSZƒòDZIE bez ogranicze≈Ñ
wait czeka okre≈õlonƒÖ liczbƒô sekund max 2s

**WA≈ªNE KLIKANIE**
NIE MA ≈ªADNYCH OGRANICZE≈É na wsp√≥≈Çrzƒôdne klikniƒôƒá
Mo≈ºesz klikaƒá w KA≈ªDE miejsce na ekranie 0 0 do max_width-1 max_height-1
Nie unikaj ≈ºadnych obszar√≥w ekranu WSZYSTKO jest klikalne
Je≈õli widzisz element na screenshocie mo≈ºesz w niego kliknƒÖƒá BEZ ≈ªADNYCH WYJƒÑTK√ìW

**ZAKO≈ÉCZENIE ZADANIA**
Kiedy sko≈Ñczysz ca≈Çe zadanie, w swojej ostatniej wiadomo≈õci tekstowej umie≈õƒá komendƒô !isfinish aby zako≈Ñczyƒá pƒôtlƒô.
WA≈ªNE: Komenda !isfinish musi byƒá w osobnej wiadomo≈õci tekstowej, nie w akcji computer_use.
Przyk≈Çad: "Zako≈Ñczy≈Çem zadanie! Wszystko dzia≈Ça poprawnie. !isfinish"`;


export async function POST(request: Request) {
  const { messages, sandboxId } = await request.json();

  const desktop = await getDesktop(sandboxId);

  const encoder = new TextEncoder();
  let isStreamClosed = false;

  const stream = new ReadableStream({
    async start(controller) {
      const sendEvent = (event: any) => {
        if (isStreamClosed) return;
        try {
          const jsonLine = JSON.stringify(event) + "\n";
          const chunk = encoder.encode(jsonLine);
          controller.enqueue(chunk);
          // Force immediate flush - no buffering
          if ((controller as any).flush) {
            (controller as any).flush();
          }
        } catch (err) {
          console.error("Error sending event:", err);
        }
      };

      try {
        const nvidia = new OpenAI({
          apiKey: NVIDIA_API_KEY,
          baseURL: "https://integrate.api.nvidia.com/v1",
        });

        // Clean messages for NVIDIA API compatibility
        const cleanedMessages = messages.map((msg: any) => {
          const { toolCalls, ...cleanMsg } = msg;
          // NVIDIA requires content to be a string, not null/undefined
          if (cleanMsg.content === null || cleanMsg.content === undefined) {
            cleanMsg.content = "";
          }
          // Convert toolCalls (camelCase) to tool_calls (snake_case) for NVIDIA
          if (toolCalls) {
            return { ...cleanMsg, tool_calls: toolCalls };
          }
          return cleanMsg;
        });

        const chatHistory: any[] = [
          { 
            role: "system", 
            content: INSTRUCTIONS
          },
          ...cleanedMessages,
        ];

        while (true) {

          const stream = await nvidia.chat.completions.create({
            model: NVIDIA_MODEL,
            messages: chatHistory,
            temperature: 0.7,
            top_p: 0.95,
            stream: true,
          });

          let fullText = "";
          let toolCalls: any[] = [];
          let currentTextChunk = "";

          for await (const chunk of stream) {
            if (chunk.choices && chunk.choices.length > 0) {
              const choice = chunk.choices[0];
              const delta = choice.delta;

              if (delta.content) {
                fullText += delta.content;
                currentTextChunk += delta.content;
                
                // Send text-delta for streaming display (filter out !isfinish)
                const displayContent = delta.content.replace('!isfinish', '');
                if (displayContent) {
                  sendEvent({
                    type: "text-delta",
                    textDelta: displayContent,
                  });
                }
                
                // Check if we should flush the current chunk as a separate message
                // Flush on sentence boundaries or after significant chunks
                const hasSentenceEnd = /[.!?]\s*$/.test(currentTextChunk.trim());
                const isLongChunk = currentTextChunk.length > 150;
                
                if ((hasSentenceEnd || isLongChunk) && currentTextChunk.trim().length > 10) {
                  // Send current chunk as a complete text message (filter out !isfinish)
                  const trimmedChunk = currentTextChunk.trim().replace('!isfinish', '').trim();
                  if (trimmedChunk) {
                    sendEvent({
                      type: "text-message",
                      content: trimmedChunk,
                    });
                    currentTextChunk = "";
                  } else {
                    // If after filtering !isfinish there's nothing left, still reset chunk
                    currentTextChunk = "";
                  }
                }
              }

              // Handle tool calls - NVIDIA mo≈ºe zwracaƒá w r√≥≈ºnych formatach
              if (delta.tool_calls) {
                for (const toolCallDelta of delta.tool_calls) {
                  const index = toolCallDelta.index ?? 0;

                  if (!toolCalls[index]) {
                    toolCalls[index] = {
                      id: toolCallDelta.id || `call_${Date.now()}_${index}`,
                      name: "",
                      arguments: "",
                    };
                  }

                  // Update name if provided
                  if (toolCallDelta.function?.name) {
                    toolCalls[index].name = toolCallDelta.function.name;
                  }

                  // Append arguments
                  if (toolCallDelta.function?.arguments) {
                    toolCalls[index].arguments += toolCallDelta.function.arguments;
                  }
                }
              }
            }
          }
          
          // Flush any remaining text chunk after streaming completes (filter out !isfinish)
          if (currentTextChunk.trim().length > 0) {
            const cleanChunk = currentTextChunk.trim().replace('!isfinish', '').trim();
            if (cleanChunk) {
              sendEvent({
                type: "text-message",
                content: cleanChunk,
              });
            }
            currentTextChunk = "";
          }
          
          // Filter out empty tool calls
          toolCalls = toolCalls.filter(tc => tc && tc.name);
          
          // Fix malformed JSON arguments from NVIDIA streaming
          toolCalls = toolCalls.map(tc => {
            if (tc.arguments) {
              let fixedArgs = tc.arguments;
              
              // Remove any trailing incomplete parts
              fixedArgs = fixedArgs.trim();
              
              // Count braces to find if JSON is incomplete
              const openBraces = (fixedArgs.match(/\{/g) || []).length;
              const closeBraces = (fixedArgs.match(/\}/g) || []).length;
              
              // If more opening braces than closing, add missing closing braces
              if (openBraces > closeBraces) {
                const missing = openBraces - closeBraces;
                fixedArgs += '}'.repeat(missing);
              }
              
              // Fix common NVIDIA streaming bugs:
              // 1. "action": "left_click, "coordinate" -> "action": "left_click", "coordinate"
              fixedArgs = fixedArgs.replace(/"([^"]+)", "([^"]+)": /g, '"$1", "$2": ');
              
              // 2. "coordinate": []512 -> "coordinate": [512
              fixedArgs = fixedArgs.replace(/: \[\](\d)/g, ': [$1');
              
              // 3. [512, 384 -> [512, 384]
              fixedArgs = fixedArgs.replace(/\[(\d+),\s*(\d+)(?!\])/g, '[$1, $2]');
              
              // 4. Ensure arrays are properly closed
              if (fixedArgs.includes('[') && !fixedArgs.includes(']')) {
                const lastBracket = fixedArgs.lastIndexOf('[');
                const afterBracket = fixedArgs.substring(lastBracket + 1);
                // If we have numbers after [, close the array
                if (/\d/.test(afterBracket)) {
                  fixedArgs = fixedArgs.replace(/\[([^\]]+)$/, '[$1]');
                }
              }
              
              // Verify it's valid JSON
              try {
                JSON.parse(fixedArgs);
                tc.arguments = fixedArgs;
              } catch (e) {
                console.error('[JSON FIX ERROR]', e, 'Original:', tc.arguments, 'Fixed:', fixedArgs);
                // If still invalid, try to salvage what we can
                // Extract action at minimum
                const actionMatch = tc.arguments.match(/"action":\s*"([^"]+)"/);
                if (actionMatch) {
                  const action = actionMatch[1];
                  
                  // Try to extract coordinate if present
                  const coordMatch = tc.arguments.match(/(\d+),\s*(\d+)/);
                  if (coordMatch && (action.includes('click') || action.includes('move'))) {
                    tc.arguments = JSON.stringify({
                      action: action,
                      coordinate: [parseInt(coordMatch[1]), parseInt(coordMatch[2])]
                    });
                  } else if (action === 'screenshot' || action === 'wait') {
                    tc.arguments = JSON.stringify({ action: action });
                  } else {
                    // Try to extract text
                    const textMatch = tc.arguments.match(/"text":\s*"([^"]+)"/);
                    if (textMatch) {
                      tc.arguments = JSON.stringify({
                        action: action,
                        text: textMatch[1]
                      });
                    } else {
                      tc.arguments = JSON.stringify({ action: action });
                    }
                  }
                }
              }
            }
            return tc;
          });
          

          let textBeforeAction = "";
          if (toolCalls.length === 0 && fullText) {
            const parsed = parseTextToolCall(fullText);
            if (parsed) {
              toolCalls = [parsed.toolCall];
              textBeforeAction = parsed.textBefore;
            }
          }

          // Check if AI wants to finish - look for !isfinish command
          const wantsToFinish = fullText && fullText.includes('!isfinish');

          if (toolCalls.length > 0) {
            // AI is calling tools - EXECUTE ONLY FIRST ONE, then break loop
            // This ensures ONE action per iteration
            const firstToolCall = toolCalls[0];
            
            if (textBeforeAction) {
              
              // Add text-only message to history
              // Note: Text was already sent via text-message events during streaming
              chatHistory.push({
                role: "assistant",
                content: textBeforeAction,
              });
              
              // NO need to send again - already sent as chunks during streaming
            }
            
            // Now prepare the tool call message
            const assistantMessage: any = {
              role: "assistant",
              content: "",  // NO TEXT HERE - action only
              tool_calls: [{
                id: firstToolCall.id,
                type: "function",
                function: {
                  name: firstToolCall.name,
                  arguments: firstToolCall.arguments,
                },
              }],
            };
            chatHistory.push(assistantMessage);

            const toolCall = firstToolCall;
            const parsedArgs = JSON.parse(toolCall.arguments);
            const toolName = toolCall.name === "computer_use" ? "computer" : "bash";

            sendEvent({
              type: "tool-input-available",
              toolCallId: toolCall.id,
              toolName: toolName,
              input: parsedArgs,
            });

            let screenshotData: any = null;
            const toolResult = await (async () => {
              try {
                let resultData: any = { type: "text", text: "" };
                let resultText = "";

                if (toolCall.name === "computer_use") {
                  const action = parsedArgs.action;

                  switch (action) {
                    case "screenshot": {
                      const response = await kernelClient.browsers.computer.captureScreenshot(desktop.session_id);
                      const blob = await response.blob();
                      const buffer = Buffer.from(await blob.arrayBuffer());
                      
                      const timestamp = new Date().toISOString();
                      const width = resolution.x;
                      const height = resolution.y;
                      const base64Image = buffer.toString("base64");

                      screenshotData = {
                        type: "image",
                        data: base64Image,
                        timestamp: timestamp,
                        width: width,
                        height: height
                      };

                      // Format for Vision API - include image in content
                      resultText = `Screenshot taken at ${timestamp}

SCREEN: ${width}√ó${height} pixels | Aspect ratio: 4:3 | Origin: (0,0) at TOP-LEFT
‚ö†Ô∏è  REMEMBER: Y=0 is at TOP, Y increases DOWNWARD (0‚Üí767)
‚ö†Ô∏è  FORMAT: [X, Y] - horizontal first, then vertical
‚ö†Ô∏è  SZCZEG√ì≈ÅOWA ANALIZA WYMAGANA: Przeanalizuj dok≈Çadnie screenshot przed kolejnymi akcjami!`;

                      resultData = {
                        type: "image",
                        data: base64Image,
                      };

                      sendEvent({
                        type: "screenshot-update",
                        screenshot: base64Image,
                      });
                      break;
                    }
                    case "wait": {
                      const duration = parsedArgs.duration || 1;
                      resultText = `Waited for ${duration} seconds`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "left_click": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.clickMouse(desktop.session_id, {
                        x,
                        y,
                        button: 'left',
                      });
                      resultText = `Left clicked at coordinates (${x}, ${y})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "double_click": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.clickMouse(desktop.session_id, {
                        x,
                        y,
                        button: 'left',
                        num_clicks: 2,
                      });
                      resultText = `Double clicked at coordinates (${x}, ${y})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "right_click": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.clickMouse(desktop.session_id, {
                        x,
                        y,
                        button: 'right',
                      });
                      resultText = `Right clicked at coordinates (${x}, ${y})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "mouse_move": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.moveMouse(desktop.session_id, {
                        x,
                        y,
                      });
                      resultText = `Moved mouse to ${x}, ${y}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "type": {
                      const textToType = parsedArgs.text;
                      await kernelClient.browsers.computer.typeText(desktop.session_id, {
                        text: textToType,
                      });
                      resultText = `Typed: ${textToType}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "key": {
                      let keyToPress = parsedArgs.text;
                      
                      // OnKernel uses X11 keysym names - convert common variants to X11 format
                      if (keyToPress === "Enter" || keyToPress === "enter") {
                        keyToPress = "Return";
                      }
                      
                      
                      await kernelClient.browsers.computer.pressKey(desktop.session_id, {
                        keys: [keyToPress],
                      });
                      resultText = `Pressed key: ${parsedArgs.text}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "scroll": {
                      const [x, y] = parsedArgs.coordinate || [512, 384];
                      const delta_x = parsedArgs.delta_x || 0;
                      const delta_y = parsedArgs.delta_y || 0;
                      await kernelClient.browsers.computer.scroll(desktop.session_id, {
                        x,
                        y,
                        delta_x,
                        delta_y,
                      });
                      resultText = `Scrolled at (${x}, ${y}) with delta_x: ${delta_x}, delta_y: ${delta_y}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "left_click_drag": {
                      const [startX, startY] = parsedArgs.start_coordinate;
                      const [endX, endY] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.dragMouse(desktop.session_id, {
                        path: [[startX, startY], [endX, endY]],
                        button: 'left',
                      });
                      resultText = `Dragged from (${startX}, ${startY}) to (${endX}, ${endY})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    default: {
                      resultText = `Unknown action: ${action}`;
                      resultData = { type: "text", text: resultText };
                      console.warn("Unknown action:", action);
                    }
                  }

                  sendEvent({
                    type: "tool-output-available",
                    toolCallId: toolCall.id,
                    output: resultData,
                  });

                  return {
                    tool_call_id: toolCall.id,
                    role: "tool",
                    content: resultText,
                    image: action === "screenshot" ? resultData.data : undefined,
                  };
                } else if (toolCall.name === "bash_command") {
                  const result = await kernelClient.browsers.process.exec(desktop.session_id, {
                    command: parsedArgs.command,
                  });

                  const stdout = result.stdout_b64 ? Buffer.from(result.stdout_b64, 'base64').toString('utf-8') : '';
                  const stderr = result.stderr_b64 ? Buffer.from(result.stderr_b64, 'base64').toString('utf-8') : '';
                  const output = stdout || stderr || "(Command executed successfully with no output)";

                  sendEvent({
                    type: "tool-output-available",
                    toolCallId: toolCall.id,
                    output: { type: "text", text: output },
                  });

                  return {
                    tool_call_id: toolCall.id,
                    role: "tool",
                    content: output,
                  };
                }
              } catch (error) {
                console.error("Error executing tool:", error);
                const errorMsg = error instanceof Error ? error.message : String(error);
                let detailedError = `Error: ${errorMsg}`;

                if (errorMsg.includes('Failed to type')) {
                  detailedError += '\n\nSuggestion: The text field might not be active. Try clicking on the text field first before typing.';
                } else if (errorMsg.includes('Failed to click') || errorMsg.includes('Failed to double click') || errorMsg.includes('Failed to right click')) {
                  detailedError += '\n\nSuggestion: The click action failed. Take a screenshot to see what happened, then try clicking again.';
                } else if (errorMsg.includes('Failed to take screenshot')) {
                  detailedError += '\n\nSuggestion: Screenshot failed. The desktop might be loading. Wait a moment and try again.';
                } else if (errorMsg.includes('Failed to press key')) {
                  detailedError += '\n\nSuggestion: Key press failed. Make sure the correct window is focused.';
                } else if (errorMsg.includes('Failed to move mouse')) {
                  detailedError += '\n\nSuggestion: Mouse movement failed. Try again.';
                } else if (errorMsg.includes('Failed to drag')) {
                  detailedError += '\n\nSuggestion: Drag operation failed. Try again with different coordinates.';
                } else if (errorMsg.includes('Failed to scroll')) {
                  detailedError += '\n\nSuggestion: Scroll failed. Make sure a scrollable window is active.';
                }

                sendEvent({
                  type: "error",
                  errorText: errorMsg,
                });

                return {
                  tool_call_id: toolCall.id,
                  role: "tool",
                  content: detailedError,
                };
              }
            })();

            // Send tool result to chat history
            // Format tool result message
            let toolMessage: any;
            if (screenshotData) {
              // KRYTYCZNE: Screenshot jako TOOL MESSAGE (potwierdzenie akcji)
              toolMessage = {
                role: "tool",
                tool_call_id: toolResult!.tool_call_id,
                content: `Screenshot captured successfully at ${screenshotData.timestamp}`
              };
              chatHistory.push(toolMessage);
              
              // KRYTYCZNE: Screenshot jako USER MESSAGE (obraz do analizy)
              // To sprawi ≈ºe AI bƒôdzie musia≈Ç odpowiedzieƒá analizujƒÖc obraz
              const userScreenshotMessage = {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: `Oto screenshot z sandboxa. Przeanalizuj go dok≈Çadnie przed podjƒôciem kolejnej akcji.\n\nSCREEN: ${screenshotData.width}√ó${screenshotData.height} pixels | Aspect ratio: 4:3 | Origin: (0,0) at TOP-LEFT\n‚ö†Ô∏è REMEMBER: Y=0 is at TOP, Y increases DOWNWARD (0‚Üí767)\n‚ö†Ô∏è FORMAT: [X, Y] - horizontal first, then vertical\n‚ö†Ô∏è CO WIDZISZ NA TYM SCREENSHOCIE? OPISZ I PODEJMIJ DECYZJƒò O KOLEJNEJ AKCJI.`
                  },
                  {
                    type: "image_url",
                    image_url: {
                      url: `data:image/png;base64,${screenshotData.data}`
                    }
                  }
                ]
              };
              chatHistory.push(userScreenshotMessage);
            } else {
              toolMessage = {
                role: "tool",
                tool_call_id: toolResult!.tool_call_id,
                content: toolResult!.content,
              };
              chatHistory.push(toolMessage);
            }        
            // INFINITE LOOP: Po akcji kontynuujemy automatycznie
            
            // Je≈õli by≈Ç screenshot, czekamy 3 sekundy aby AI mog≈Ço przeanalizowaƒá
            if (screenshotData) {
              await new Promise(resolve => setTimeout(resolve, 3000));
            }
            
            // Po ka≈ºdej akcji resetujemy currentTextId aby nastƒôpna wiadomo≈õƒá by≈Ça osobna
            // To zapewnia ≈ºe ka≈ºda akcja rozdziela wiadomo≈õci
          } else {
            // No tool calls - AI is just sending text
            if (fullText) {
              // Check if AI wants to finish BEFORE adding to history
              if (wantsToFinish) {
                
                // Remove !isfinish from the text before sending
                const cleanText = fullText.replace('!isfinish', '').trim();
                
                if (cleanText) {
                  chatHistory.push({
                    role: "assistant",
                    content: cleanText,
                  });
                  
                  // Text was already sent as chunks during streaming
                  // NO need to send again
                }
                
                // Send finish event
                sendEvent({
                  type: "finish",
                  content: "Task completed",
                });
                break;
              }
              
              // Normal text message - add to history and continue loop
              chatHistory.push({
                role: "assistant",
                content: fullText,
              });
              
              // Text was already sent as chunks during streaming via text-message events
              // NO need to send again to avoid duplication
              
            }
            
            // Continue loop - AI will execute next action or send another message
          }
        }
      } catch (error) {
        console.error("Chat API error:", error);
        await killDesktop(sandboxId);
        sendEvent({
          type: "error",
          errorText: String(error),
        });
      } finally {
        if (!isStreamClosed) {
          isStreamClosed = true;
          controller.close();
        }
      }
    },
  });

  return new Response(stream, {
    headers: {
      "Content-Type": "text/plain; charset=utf-8",
      "Cache-Control": "no-cache, no-store, must-revalidate, max-age=0",
      "Pragma": "no-cache",
      "Expires": "0",
      "X-Accel-Buffering": "no",
      "Transfer-Encoding": "chunked",
      "Connection": "keep-alive",
    },
  });
}